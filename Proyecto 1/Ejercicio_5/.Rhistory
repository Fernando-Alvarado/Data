#haciedno la grafia de nuestras variables aleatorias
ggplot(data, aes(x=varx, y=vary)) + geom_point() + theme_minimal()
#Hagamos sus calculos de su media y varianza
# Calcular la media de varx y vary
media_varx <- mean(data$varx)
media_vary <- mean(data$vary)
# Calcular la varianza de varx y vary
varianza_varx <- var(data$varx)
varianza_vary <- var(data$vary)
# Calcular la desviación estándar de varx y vary
desviacion_varx <- sd(data$varx)
desviacion_vary <- sd(data$vary)
# Imprimir los resultados
print(paste("Media de varx: ", media_varx))
print(paste("Media de vary: ", media_vary))
print(paste("Varianza de varx: ", varianza_varx))
print(paste("Varianza de vary: ", varianza_vary))
print(paste("Desviación estándar de varx: ", desviacion_varx))
print(paste("Desviación estándar de vary: ", desviacion_vary))
library(MASS)
summary(Cars93)
print(Cars93$Weight)
ggplot(Cars93, aes(y = Weight)) +
geom_boxplot() +
labs(title = "Boxplot de varx", y = "Valores")
summary(Cars93)
View(data)
summary(Cars93)
Cars93
a <- Cars93
View(a)
ggplot(Cars93, aes(y = Weight)) +
geom_boxplot() +
labs(title = "Boxplot de varx", y = "Valores")
problema <- c(4,3,1,6,7,8,5,5,6)
print(var(problema))
print(sd(problema))
datos <- c(85, 37, 48, 64, 73, 54, 104, 92, 85, 95)
# Calcular la media geométrica
media_geometrica <- prod(datos)^(1/length(datos))
# Imprimir la media geométrica
print(media_geometrica)
rm(list = ls(all.names = TRUE))
gc()
library(ALSM)
library(ALSM)
library(ALSM)
library(ALSM)
install.packages("devtools")
install.packages("ALSM")
library(ALSM)
install.packages("ALSM")
devtools::install_github("ALSM")
devtools::install_github("usuario/repositorio")
devtools::install_github("ALSM")
install.packages("ALSM")
library(ALSM)
install.packages("https://cran.r-project.org/src/contrib/Archive/ALSM/ALSM_0.1.9.tar.gz", repos = NULL, type = "source")
# Ejemplo de la Compañía Toluca
# Intervalos de confianza y pruebas de hipótesis
rm(list = ls(all.names = TRUE))
library(ALSM)
# Ejemplo de la Compañía Toluca
# Intervalos de confianza y pruebas de hipótesis
rm(list = ls(all.names = TRUE))
gc()
install.packages("devtools")
install.packages("ALSM")
library(ALSM)
Datos=TolucaCompany
head(Datos)
str(Datos)
par(mar=c(4,4,1,1))
par(mfrow=c(1,1))
plot(y~x, data=Datos, cex=.9, cex.axis=.7, cex.lab=.8)
###Alternativa interactiva.
require(ggplot2)
require(ggiraph)
require(ggiraphExtra)
ggPoints(aes(x=x,y=y),smooth=TRUE, data=Datos,interactive=TRUE,se=FALSE, method = "lm")
rm(list = ls(all.names = TRUE))
gc()
rm(list = ls(all.names = TRUE))
gc()
### Continuación de ejemplo. Compañía Toluca
### Herramientas de diagnóstico sobre homocedasticidad
library(ALSM)
rm(list = ls(all.names = TRUE))
gc()
#Datos University
#Valor total de la universidad (empresa) vs los costos de la colegiatura
library(Ecdat)
Datos <- University
help(University)
#Y nassets
#X stfees
head(Datos)
str(Datos)
library(latex2exp)
par(mfrow=c(1,1))
par(mar=c(4, 5, 1, 1))
plot(Datos$stfees, Datos$nassets, xlab = TeX("$stfees$"), ylab=TeX("$nassets$") )
fit=lm(nassets~stfees, data=Datos)
summary(fit)
par(mfrow=c(1,1))
par(mar=c(4, 5, 1, 1))
plot(fit, 3)
library(broom)
Datosfit=augment(fit)
head(Datosfit)
par(mar=c(4, 5, 1, 1))
par(mfrow=c(1,1))
plot(Datosfit$.fitted, Datosfit$.std.resid, xlab = TeX("$\\widehat{y}$"), ylab=TeX("$e_{s}$")   )
### Pruebas de hipótesis
### H0: varianza no depende de forma lineal en x vs  Ha: varianza depende de forma lineal en x
### Se busca no rechazar, es decir,
### que sea plausible (no se encontró evidencia en contra) asumir que la varianza no depende de forma lineal de x
### i.e. p-value mayor a significancia.
#Usa residuales studentilizados
library(lmtest)
lmtest::bptest(fit)
#Usa residuales estandarizados
library(car)
car::ncvTest(fit)
summary(Datos$nassets)
#### Uso de transformaciones Box-Cox
#### Función powerTransform del paquete car
#### Cuando la variable "y" es estrictamente positiva
#Se prefiere un valor de lambda conocido para no complicar mucho la interpretaci?n
summary(powerTransform(fit))
#El intervalo sugiere que lambda=.2 podría ser una opción (notar que se rechaza lambda=0 y 1)
Datos$nassets_lambda0=bcPower(Datos$nassets, .2)
Datos$nassetsBC=(Datos$nassets^(.2)-1)/.2
par(mar=c(4, 5, 1, 1))
par(mfrow=c(1,1))
plot(Datos$stfees, Datos$nassetsBC, xlab = TeX("$stfees$"), ylab=TeX("$(y^{.2}-1)/.2$") )
fit2=lm(nassetsBC~stfees, data=Datos)
summary(fit2)
par(mfrow=c(1,1))
par(mar=c(4, 5, 1, 1))
plot(fit2, 3)
lmtest::bptest(fit2)
car::ncvTest(fit2)
summary(powerTransform(fit2))
#Para datos negativos o con ceros se puede usar una constante gamma positiva para trabajar con valores positivos
#powerTransform(,  family="bcnPower")
summary(powerTransform(fit,  family="bcnPower"))
Datos$nassetsBCalt=bcnPower(Datos$nassets, lambda=0, gamma=16677.21)
fit3=lm(nassetsBCalt~stfees, data=Datos)
plot(Datos$stfees, Datos$nassetsBCalt, xlab = TeX("$stfees$"), ylab=TeX("$ln(z)$") )
plot(fit3, 3)
lmtest::bptest(fit3)
car::ncvTest(fit3)
#Una opción alternativa es transformar los datos sumandole la constante positiva antes de usar la transformación BoxCox simple
# Nota. En este modelo se puede presentar como resultado
# una gráfica con el ajuste del modelo, pero para facilidad del usuario
# en la escala original, que corresponde a la mediana, Med(y;x)
par(mfrow=c(1,2))
par(mar=c(4, 5, 1, 1))
fit2yprima <- function(X2) {fit2$coef[1]+ fit2$coef[2]*X2}
fit2y <- function(X2) {((fit2$coef[1]+ fit2$coef[2]*X2)*.2+1)^5}
# En la escala transformada la curva (recta) corresponde
# a la estimación de E(y*;x)=Med(y*;x)
plot(Datos$stfees,Datos$nassetsBC, xlab = TeX("$stfees$"), ylab=TeX("$y^{*}$") )
curve(fit2yprima, from = min(Datos$stfees), to = max(Datos$stfees),
col = "red", add = T)
# En la escala original la curva corresponde
# a la estimación de Med(y;x)
plot(Datos$stfees, Datos$nassets, xlab = TeX("$stfees$"), ylab=TeX("$nassets$") )
curve(fit2y, from = min(Datos$stfees), to = max(Datos$stfees),
col = "red", add = T)
#Problema 6 de los Pinguinos, echo por: Fernando Alvarado Palacios
require(dplyr)
#Limpiando la consola para poder trabajar mejor
rm(list = ls(all.names = TRUE))
gc()
#Datos sobre los pinguinos
x = c(79, 93, 100, 105, 85, 101, 96, 96, 109, 70, 71, 87)
y = c(119, 142, 158, 157, 136, 151, 139, 142, 165, 117, 123, 130)
Datos6 = data.frame(cbind(x, y))
kable(t(Datos6)) %>%
kable_styling(bootstrap_options = "striped", full_width = F)
require(dplyr)
library(kableExtra)
install.packages("kableExtra")
require(dplyr)
library(kableExtra)
#Limpiando la consola para poder trabajar mejor
rm(list = ls(all.names = TRUE))
gc()
#Datos sobre los pinguinos
x = c(79, 93, 100, 105, 85, 101, 96, 96, 109, 70, 71, 87)
y = c(119, 142, 158, 157, 136, 151, 139, 142, 165, 117, 123, 130)
Datos6 = data.frame(cbind(x, y))
kable(t(Datos6)) %>%
kable_styling(bootstrap_options = "striped", full_width = F)
#Ajusstando el modelo de regresion lineal
print(Datos6)
modelo = lm(y ~ x, data = Datos6)
fit(modelo)
#Ajusstando el modelo de regresion lineal
modelo = lm(y ~ x, data = Datos6)
summary(modelo)
modelo = lm(y ~ x, data = Datos6)
summary(modelo)
#-- Con este primer vistazo podemos observar que si tienen relacion las variables x, y en el modelo de regresion lineal
#Graficando el modelo de regresion lineal
ggplot(Datos6, aes(x = x, y = y)) +
geom_point() +
geom_smooth(method = "lm", se = F) +
labs(title = "Modelo de regresion lineal",
x = "x peso del huevo menor",
y = "y peso del huevo mayor") +
theme_minimal()
library(ggplot2)
modelo = lm(y ~ x, data = Datos6)
summary(modelo)
#-- Con este primer vistazo podemos observar que si tienen relacion las variables x, y en el modelo de regresion lineal
#Graficando el modelo de regresion lineal
ggplot(Datos6, aes(x = x, y = y)) +
geom_point() +
geom_smooth(method = "lm", se = F) +
labs(title = "Modelo de regresion lineal",
x = "x peso del huevo menor",
y = "y peso del huevo mayor") +
theme_minimal()
plot(modelo, 3)
bptest(modelo)
lmtest::bptest(modelo)
plot(modelo, 1)
#-- Con esta grafica podemos observar que no se esta cumpliendo el supuesto de linealidad, por lo que tendremso que hacer una transformacion de los datos
#-- # se va a hacer a partir de la familia de transformaciones Box-Tidwell
boxTidwell(y~x, data=modelo)
library(car) # checar linealidad
#-- Con esta grafica podemos observar que no se esta cumpliendo el supuesto de linealidad, por lo que tendremso que hacer una transformacion de los datos
#-- # se va a hacer a partir de la familia de transformaciones Box-Tidwell
boxTidwell(y~x, data=modelo)
#Librerias necesarias para el ejercicio
library(dplyr)
library(kableExtra)
library(ggplot2)
library(lmtest) # checar homocedasticidad
library(car) # checar linealidad
plot(modelo, 1)
#-- Con esta grafica podemos observar que no se esta cumpliendo el supuesto de linealidad, por lo que tendremso que hacer una transformacion de los datos
#-- # se va a hacer a partir de la familia de transformaciones Box-Tidwell
boxTidwell(y~x, data=modelo)
#-- Con esta grafica podemos observar que no se esta cumpliendo el supuesto de linealidad, por lo que tendremso que hacer una transformacion de los datos
#-- # se va a hacer a partir de la familia de transformaciones Box-Tidwell
boxTidwell(y~x, data=Datos6) #No pongas el modelo, si no los datos
#Problema 6 de los Pinguinos, echo por: Fernando Alvarado Palacios
#Librerias necesarias para el ejercicio
library(dplyr)
library(kableExtra)
library(ggplot2)
library(lmtest) # checar homocedasticidad
library(car) # checar linealidad
#Limpiando la consola para poder trabajar mejor
rm(list = ls(all.names = TRUE))
gc()
#Datos sobre los pinguinos
x = c(79, 93, 100, 105, 85, 101, 96, 96, 109, 70, 71, 87)
y = c(119, 142, 158, 157, 136, 151, 139, 142, 165, 117, 123, 130)
Datos6 = data.frame(cbind(x, y))
kable(t(Datos6)) %>%
kable_styling(bootstrap_options = "striped", full_width = F)
#Ajusstando el modelo de regresion lineal
modelo = lm(y ~ x, data = Datos6)
summary(modelo)
#-- Con este primer vistazo podemos observar que si tienen relacion las variables x, y en el modelo de regresion lineal
#Graficando el modelo de regresion lineal
grafica_modelo = function(varx) {
ggplot(Datos6, aes(x = varx, y = y)) + #Creando la grafica de nuetra regresion lineal, agustado con los datos de los pinguinos
geom_point() +
geom_smooth(method = "lm", se = F) +
labs(title = "Modelo de regresion lineal",
x = "x peso del huevo menor",
y = "y peso del huevo mayor") +
theme_minimal()
}
grafica_modelo(x)
#Verificando si se cumplen los supuestos del modelo de regresion lineal
#Checando  homocedasticidad por medio de la grafica propia de R
plot(modelo, 3)#Checar homocedasticidad, por defecto en R
#Aplicando la una prueba de hipotesis para la homocedasticidad
lmtest::bptest(modelo)
#-- Con esta prueba de Hipoteis como nuestro p-value es 0.5036, podemos concluir que tenemos homocedasticidad
#Checando linealidad  por medio de la grafica de R
plot(modelo, 1)#Checar linealidad, por defecto en R
#-- Con esta grafica podemos observar que no se esta cumpliendo el supuesto de linealidad, por lo que tendremso que hacer una transformacion de los datos
#-- # se va a hacer a partir de la familia de transformaciones Box-Tidwell
boxTidwell(y~x, data=Datos6) #No pongas el modelo, si no los datos
#-- Con esta prueba podemos observar que es necesrio hacer una transformacion de los datos
#Ajustando nuestro modelo de Regresion Lineal con una transformacion
lambda <- boxTidwell_result$estimate[1]  # Extraer el valor de lambda de la prueba de Box-Tidwell
summary(modelo_transformado) #Checando el resumen del modelo
#Volciendo a hacer el modelo de regresion
modelo_transformado = lm(y ~ x_transformed, data = Datos6)
lambda <- boxTidwell_result$estimate[1]  # Extraer el valor de lambda de la prueba de Box-Tidwell
lambda <- boxTidwell_result$estimate[1]  # Extraer el valor de lambda de la prueba de Box-Tidwell
library(dplyr)
library(kableExtra)
library(ggplot2)
library(lmtest) # checar homocedasticidad
library(car) # checar linealidad
library(dplyr)
library(kableExtra)
library(ggplot2)
library(lmtest) # checar homocedasticidad
library(car) # checar linealidad
#Limpiando la consola para poder trabajar mejor
rm(list = ls(all.names = TRUE))
gc()
#Datos sobre los pinguinos
x = c(79, 93, 100, 105, 85, 101, 96, 96, 109, 70, 71, 87)
y = c(119, 142, 158, 157, 136, 151, 139, 142, 165, 117, 123, 130)
Datos6 = data.frame(cbind(x, y))
kable(t(Datos6)) %>%
kable_styling(bootstrap_options = "striped", full_width = F)
#Ajusstando el modelo de regresion lineal
modelo = lm(y ~ x, data = Datos6)
summary(modelo)
#-- Con este primer vistazo podemos observar que si tienen relacion las variables x, y en el modelo de regresion lineal
#Graficando el modelo de regresion lineal
grafica_modelo = function(varx) {
ggplot(Datos6, aes(x = varx, y = y)) + #Creando la grafica de nuetra regresion lineal, agustado con los datos de los pinguinos
geom_point() +
geom_smooth(method = "lm", se = F) +
labs(title = "Modelo de regresion lineal",
x = "x peso del huevo menor",
y = "y peso del huevo mayor") +
theme_minimal()
}
grafica_modelo(x)
plot(modelo, 3)#Checar homocedasticidad, por defecto en R
lmtest::bptest(modelo)
plot(modelo, 1)#Checar linealidad, por defecto en R
#-- Con esta grafica podemos observar que no se esta cumpliendo el supuesto de linealidad, por lo que tendremso que hacer una transformacion de los datos
#-- # se va a hacer a partir de la familia de transformaciones Box-Tidwell
boxTidwell(y~x, data=Datos6) #No pongas el modelo, si no los datos
lambda <- boxTidwell_result$estimate[1]  # Extraer el valor de lambda de la prueba de Box-Tidwell
#-- Con esta grafica podemos observar que no se esta cumpliendo el supuesto de linealidad, por lo que tendremso que hacer una transformacion de los datos
#-- # se va a hacer a partir de la familia de transformaciones Box-Tidwell
pruebaBox_Tid <- boxTidwell(y~x, data=Datos6) #No pongas el modelo, si no los datos
pruebaBox_Tid
lambda <- pruebaBox_Tid$estimate[1]  # Extraer el valor de lambda de la prueba de Box-Tidwell
Datos6$x_transformed <- Datos$x^lambda    # Aplicar la transformación
#Volciendo a hacer el modelo de regresion
modelo_transformado = lm(y ~ x_transformed, data = Datos6)
Datos6$x_transformed <- Datos6$x^lambda    # Aplicar la transformación
Datos6$x_transformed <- Datos6$x^lambda    # Aplicar la transformación
lambda
pruebaBox_Tid
lambda <- pruebaBox_Tid$estimate[0]  # Extraer el valor de lambda de la prueba de Box-Tidwell
lambda
lambda <- pruebaBox_Tid$estimate[1]  # Extraer el valor de lambda de la prueba de Box-Tidwell
lambda <- pruebaBox_Tid$lambda  # Extraer el valor de lambda de la prueba de Box-Tidwell
lambda
lambda <- pruebaBox_Tid$estimate[1]  # Extraer el valor de lambda de la prueba de Box-Tidwell
lambda
lambda <- 3.603
Datos6$x_transformed <- Datos6$x^lambda    # Aplicar la transformación
Datos6
modelo_transformado = lm(y ~ x_transformed, data = Datos6)
summary(modelo_transformado) #Checando el resumen del modelo
grafica_modelo(x_transformed) #Graficando el modelo de regresion lineal transformado
Datos6
#Volciendo a hacer el modelo de regresion
modelo_transformado = lm(y ~ x_transformed, data = Datos6)
summary(modelo_transformado) #Checando el resumen del modelo
grafica_modelo(Datos6$x_transformed) #Graficando el modelo de regresion lineal transformado
#Problema 5, talba Anova echo por: Fernando Alvarado Palacios
#Limpiando la consola para poder trabajar mejor
rm(list = ls(all.names = TRUE))
gc()
#Librerias necesarias para el ejercicio
library(kableExtra)
library(ggplot2) #Graficar
library(lmtest) # checar homocedasticidad
library(car) # checar linealidad
library(broom) # checar normalidad y calcular residuales
library(lawstat) #libreria para checar aleatoriedad
library(tidyverse) #Libreria para hacer la manipulacion de los datos
library(dplyr) #Meanejo de datos
library(multcomp) #Libreria para hacer pruebas de hipotesis
#Estableciendo el directorio de trabajo
getwd()
setwd("C://Users//ferna//Documents//Estadisitica_2//Data//Proyecto 1//Ejercicio_5")#Modificar esta linea en caso de que no se encuentre en la misma carpeta
#Cargando nuestros datos
dataMed = read.csv("./Ejercicio5A.csv") #Archivo CSV con los datos de los medicamentos
#Donde Y es un índice de carga viral y Med es una variable con dos niveles dependiendo si se aplicó o no el nuevo medicamento y Edad es la edad del paciente
str(dataMed) #Cargando una vista previa de nuestros datos
#--Podemos observar que que tenemos 3 variables,  una de tipo numerico y dos de tipo caracter
#Vamos a modificar los datos de tipo caracter a categoricos para poder trabajar con ellos
dataMed$Med = as.factor(dataMed$Med)
dataMed$Edad = as.factor(dataMed$Edad)
str(dataMed) #Cargando una vista previa de nuestros datos
#Vamos a hacer una filtracion de los dato
dataFil = dataMed %>% dplyr::select(Y, Med)  %>% filter (Med %in% c("Si", "No"))  #Filtrando los datos para solo tener dos categorias
levels(dataFil$Med) <- list(Si = "Si", No = "No") #Cambiamos los nombres de las categorias
dataFil
#Inciso I, vamos a realizar un analisis exploratorio de los datos, para ellos vamos a realizar un boxplot
boxplot(Y ~ Med, data = dataFil, col = "white", outline=FALSE)
stripchart(Y ~ Med, data = dataFil,
method = "jitter",
pch = 19,
col = 2:4,
vertical = TRUE,
add = TRUE)
#--Con este box-plot podemos ver como se estan distribuyendo los datos, podemos ver que los datos de la categoria "Si" estan mas dispersos que los de la categoria "No"
#Inciso II, vamos a escribir nuestra prueba de hipotesis para ver si la carga viral es mayor en los pacientes que se les aplico el medicamento
#   Sea x nuestra varible cstegorica => x=0 si no se aplico el medicamento y x=1 si se aplico el medicamento
#   De nuestro modelo de regresion lineal tendremos que:
#   E(Y|x=0) = b0 y
#   E(Y|x=1) = b0 + b1
#   Si se suministro, tengan mayor nivel de anticuerpos, lo podemos modelar como:
#   E(Y|x=1) >= E(Y|x=0) => b0 + b1 >= b0 => b1 >= 0
#   Por lo que nuestra prueba de hipotesis sera:
#   H_o: b1 <= 0 vs H_a: b1 > 0
#Inciso III, vamos a crear nuestro modelo de regresion lineal y ver si lo que nos dice la farmaceutica es cierto
#Crenado nuestro modelo de regresion lineal
modelo = lm(Y ~ Med, data = dataFil) #Modelo base con el vamos a trbaajar
summary(modelo) #Cargando un resumen de nuestro modelo, con esto podemos ver que Y y Med tienen una relacion
#Verificando los Supuestos del modelo de regresion lineal
plot(modelo, 3)#Checar homocedasticidad, por defecto en R
lmtest::bptest(modelo)
#-- Con esta prueba de Hipoteis como nuestro p-value es 0.2594, podemos concluir que tenemos homocedasticidad
car::ncvTest(modelo) #Otra funcion para checar homocedasticidad
plot(modelo, 2)#Checar normalidad, por defecto en R
ResiduosModelo = augment(modelo) #Arreglando los residuales de nuestro modelo
head(ResiduosModelo) #Veamos que nos regresa la funcion augment
shapiro.test(ResiduosModelo$.std.resid)
#El valor de este pruena fue de 0.06098, casi se rechaza, ver si haciendo una transformacion a los datos se puede mejorar
#Otra prueba ms robusta de normalidad en cada grupo y sobre la variable dependiente
dataFil
shapiro.test(dataFil$Y[dataFil$Med=="Si"])
nortest::lillie.test(dataFil$Y[dataFil$Med=="Si"])
tseries::jarque.bera.test(dataFil$Y[dataFil$Med=="Si"])
shapiro.test(dataFil$Y[dataFil$Med=="No"])
nortest::lillie.test(dataFil$Y[dataFil$Med=="No"])
tseries::jarque.bera.test(dataFil$Y[dataFil$Med=="No"])
#Con estas preubas individuales tuvimos un mejor resultado, por lo que podemos concluir que tenemos normalidad en cada grupo y sobre la varible dependiente
#Ya con estas pruebas podemos concluir que se cumple con los supuestos del modelo de regresion lineal
#resumen del modelo y tests, para ver que tan bueno es
summary(modelo)
AIC(modelo)
BIC(modelo)
#Creando la prueba de hipotesis para comprobar la prueba la hipotesis de relacion entre la carga viral y el medicamento
#   H_o: b1 <= 0 vs H_a: b1 > 0
MatPrueba1 = matrix(c(0,1), ncol=2, nrow=1)
c=0
prueba1 = glht(modelo, linfct=MatPrueba1, rhs=c, alternative ="greater")
summary(prueba1)
#Con esta prueba podemos ver que es cierto, si hay una relacion positiva entre la carga viral y la aplicacion de la vacuna
#por lo que en un principio la farmaceutica tiene razon y el medicamento funciona
#Inciso IV, Vemos que el costo del medicamento es considerable, y nos dieron una nueva variable, la edad, vamos a ver si la edad influye en la carga viral
#Primero, vamos a hacer un analisis descriptivo de los datos, para ver si la edad puede influir en el funcionameinto del medicamento
summary(dataMed) #Cargando un resumen de nuestros
ggplot(data = dataMed, aes(x = interaction(Med, Edad), y = Y)) +
geom_boxplot() +
labs(x = "Edad y si estaban vacunado", y = "Carga retroviral") +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
stripchart(Y ~ Med, data = dataMed,
method = "jitter",
pch = 19,
col = 2:4,
vertical = TRUE,
add = TRUE)
#-----------------------Duda de como hacer la comparacion bien
#Inciso V, vamos a hacer un modelo de regresion y una prueba de hipotesis, para verificar nuestra sospecha de que la edad influye en el funcionamento del medicamento y por consiguiente en la carga viral
#Como tenemos mas personas en el caso donde son >60, vamos a hacer el modelo en base a esa poblacion
dataFil2 = dataMed %>% dplyr::select(Y, Med, Edad)  %>% filter (Edad== ">60")   #Filtrando los datos para solo tener dos categorias
summary(dataFil2) #Cargando un resumen de nuestros
#Volviendo a hacer nuestro modelo de regresion lineal
modeloEdad = lm(Y ~ Med, data = dataFil2) #Modelo base con el vamos a trbaajar
summary(modeloEdad) #Cargando un resumen de nuestro modelo, con esto podemos ver que Y y Med tienen una relacion de nuevo filtrando con la edad
#Checando pruebas del modelo de regresion de nuevo
plot(modeloEdad, 3)#Checar homocedasticidad, por defecto en R
lmtest::bptest(modeloEdad)
#-- Con esta prueba de Hipoteis como nuestro p-value es 0.4251, podemos concluir que tenemos homocedasticidad
car::ncvTest(modeloEdad) #Otra funcion para checar homocedasticidad
plot(modeloEdad, 2)#Checar normalidad, por defecto en R
ResiduosModeloEdad = augment(modeloEdad) #Arreglando los residuales de nuestro modelo
head(ResiduosModeloEdad) #Veamos que nos regresa la funcion augment
shapiro.test(ResiduosModeloEdad$.std.resid)
#El valor de este pruena fue de 0.8304, casi se rechaza, ver si haciendo una transformacion a los datos se puede mejorar
#Otra prueba mas robusta de normalidad en cada grupo y sobre la variable dependiente
dataFil2
shapiro.test(dataFil2$Y[dataFil2$Med=="Si"])
nortest::lillie.test(dataFil2$Y[dataFil2$Med=="Si"])
tseries::jarque.bera.test(dataFil2$Y[dataFil2$Med=="Si"])
shapiro.test(dataFil2$Y[dataFil2$Med=="No"])
nortest::lillie.test(dataFil2$Y[dataFil2$Med=="No"])
tseries::jarque.bera.test(dataFil2$Y[dataFil2$Med=="No"])
#Con estas preubas individuales tuvimos un mejor resultado, por lo que podemos concluir que tenemos normalidad en cada grupo y sobre la varible dependiente
#Ya con estas pruebas podemos concluir que se cumple con los supuestos del modelo de regresion lineal
#resumen del modelo y tests, para ver que tan bueno es
summary(modeloEdad)
AIC(modeloEdad)
BIC(modeloEdad) #Parece curioso, pero este modelo nos dio una mejor puntacion que el anterior que tenia mas datos
#Haciedno la misma preuba de hipotesis que hicimos en el inciso III para ver si el medicamento sigue funcionando en relacion a la carga viral
#Donte tambien estamos comparando H_o: b1 <= 0 vs H_a: b1 > 0
MatPrueba2 = matrix(c(0,1), ncol=2, nrow=1)
c=0
prueba2 = glht(modeloEdad, linfct=MatPrueba2, rhs=c, alternative ="greater")
summary(prueba2)
#En este caso estamos viendo que se acepto h_0, lo que significa que no hay una relacion positiva entre la carga viral y la aplicacion del medicamento
#Por lo que podriamos concluir que el medicamento no funciona y para "maquillar", los datos, agregaron poblacion joven
MatPrueba1 = matrix(c(0,1), ncol=2, nrow=1)
c=0
prueba1 = glht(modelo, linfct=MatPrueba1, rhs=c, alternative ="greater")
summary(prueba1)
