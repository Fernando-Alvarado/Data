### H0: varianza no depende de forma lineal en x vs  Ha: varianza depende de forma lineal en x
### Se busca no rechazar, es decir,
### que sea plausible (no se encontró evidencia en contra) asumir que la varianza no depende de forma lineal de x
### i.e. p-value mayor a significancia.
#Usa residuales studentilizados
library(lmtest)
lmtest::bptest(fit)
#Usa residuales estandarizados
library(car)
car::ncvTest(fit)
summary(Datos$nassets)
#### Uso de transformaciones Box-Cox
#### Función powerTransform del paquete car
#### Cuando la variable "y" es estrictamente positiva
#Se prefiere un valor de lambda conocido para no complicar mucho la interpretaci?n
summary(powerTransform(fit))
#El intervalo sugiere que lambda=.2 podría ser una opción (notar que se rechaza lambda=0 y 1)
Datos$nassets_lambda0=bcPower(Datos$nassets, .2)
Datos$nassetsBC=(Datos$nassets^(.2)-1)/.2
par(mar=c(4, 5, 1, 1))
par(mfrow=c(1,1))
plot(Datos$stfees, Datos$nassetsBC, xlab = TeX("$stfees$"), ylab=TeX("$(y^{.2}-1)/.2$") )
fit2=lm(nassetsBC~stfees, data=Datos)
summary(fit2)
par(mfrow=c(1,1))
par(mar=c(4, 5, 1, 1))
plot(fit2, 3)
lmtest::bptest(fit2)
car::ncvTest(fit2)
summary(powerTransform(fit2))
#Para datos negativos o con ceros se puede usar una constante gamma positiva para trabajar con valores positivos
#powerTransform(,  family="bcnPower")
summary(powerTransform(fit,  family="bcnPower"))
Datos$nassetsBCalt=bcnPower(Datos$nassets, lambda=0, gamma=16677.21)
fit3=lm(nassetsBCalt~stfees, data=Datos)
plot(Datos$stfees, Datos$nassetsBCalt, xlab = TeX("$stfees$"), ylab=TeX("$ln(z)$") )
plot(fit3, 3)
lmtest::bptest(fit3)
car::ncvTest(fit3)
#Una opción alternativa es transformar los datos sumandole la constante positiva antes de usar la transformación BoxCox simple
# Nota. En este modelo se puede presentar como resultado
# una gráfica con el ajuste del modelo, pero para facilidad del usuario
# en la escala original, que corresponde a la mediana, Med(y;x)
par(mfrow=c(1,2))
par(mar=c(4, 5, 1, 1))
fit2yprima <- function(X2) {fit2$coef[1]+ fit2$coef[2]*X2}
fit2y <- function(X2) {((fit2$coef[1]+ fit2$coef[2]*X2)*.2+1)^5}
# En la escala transformada la curva (recta) corresponde
# a la estimación de E(y*;x)=Med(y*;x)
plot(Datos$stfees,Datos$nassetsBC, xlab = TeX("$stfees$"), ylab=TeX("$y^{*}$") )
curve(fit2yprima, from = min(Datos$stfees), to = max(Datos$stfees),
col = "red", add = T)
# En la escala original la curva corresponde
# a la estimación de Med(y;x)
plot(Datos$stfees, Datos$nassets, xlab = TeX("$stfees$"), ylab=TeX("$nassets$") )
curve(fit2y, from = min(Datos$stfees), to = max(Datos$stfees),
col = "red", add = T)
#Problema 6 de los Pinguinos, echo por: Fernando Alvarado Palacios
require(dplyr)
#Limpiando la consola para poder trabajar mejor
rm(list = ls(all.names = TRUE))
gc()
#Datos sobre los pinguinos
x = c(79, 93, 100, 105, 85, 101, 96, 96, 109, 70, 71, 87)
y = c(119, 142, 158, 157, 136, 151, 139, 142, 165, 117, 123, 130)
Datos6 = data.frame(cbind(x, y))
kable(t(Datos6)) %>%
kable_styling(bootstrap_options = "striped", full_width = F)
require(dplyr)
library(kableExtra)
install.packages("kableExtra")
require(dplyr)
library(kableExtra)
#Limpiando la consola para poder trabajar mejor
rm(list = ls(all.names = TRUE))
gc()
#Datos sobre los pinguinos
x = c(79, 93, 100, 105, 85, 101, 96, 96, 109, 70, 71, 87)
y = c(119, 142, 158, 157, 136, 151, 139, 142, 165, 117, 123, 130)
Datos6 = data.frame(cbind(x, y))
kable(t(Datos6)) %>%
kable_styling(bootstrap_options = "striped", full_width = F)
#Ajusstando el modelo de regresion lineal
print(Datos6)
modelo = lm(y ~ x, data = Datos6)
fit(modelo)
#Ajusstando el modelo de regresion lineal
modelo = lm(y ~ x, data = Datos6)
summary(modelo)
modelo = lm(y ~ x, data = Datos6)
summary(modelo)
#-- Con este primer vistazo podemos observar que si tienen relacion las variables x, y en el modelo de regresion lineal
#Graficando el modelo de regresion lineal
ggplot(Datos6, aes(x = x, y = y)) +
geom_point() +
geom_smooth(method = "lm", se = F) +
labs(title = "Modelo de regresion lineal",
x = "x peso del huevo menor",
y = "y peso del huevo mayor") +
theme_minimal()
library(ggplot2)
modelo = lm(y ~ x, data = Datos6)
summary(modelo)
#-- Con este primer vistazo podemos observar que si tienen relacion las variables x, y en el modelo de regresion lineal
#Graficando el modelo de regresion lineal
ggplot(Datos6, aes(x = x, y = y)) +
geom_point() +
geom_smooth(method = "lm", se = F) +
labs(title = "Modelo de regresion lineal",
x = "x peso del huevo menor",
y = "y peso del huevo mayor") +
theme_minimal()
plot(modelo, 3)
bptest(modelo)
lmtest::bptest(modelo)
plot(modelo, 1)
#-- Con esta grafica podemos observar que no se esta cumpliendo el supuesto de linealidad, por lo que tendremso que hacer una transformacion de los datos
#-- # se va a hacer a partir de la familia de transformaciones Box-Tidwell
boxTidwell(y~x, data=modelo)
library(car) # checar linealidad
#-- Con esta grafica podemos observar que no se esta cumpliendo el supuesto de linealidad, por lo que tendremso que hacer una transformacion de los datos
#-- # se va a hacer a partir de la familia de transformaciones Box-Tidwell
boxTidwell(y~x, data=modelo)
#Librerias necesarias para el ejercicio
library(dplyr)
library(kableExtra)
library(ggplot2)
library(lmtest) # checar homocedasticidad
library(car) # checar linealidad
plot(modelo, 1)
#-- Con esta grafica podemos observar que no se esta cumpliendo el supuesto de linealidad, por lo que tendremso que hacer una transformacion de los datos
#-- # se va a hacer a partir de la familia de transformaciones Box-Tidwell
boxTidwell(y~x, data=modelo)
#-- Con esta grafica podemos observar que no se esta cumpliendo el supuesto de linealidad, por lo que tendremso que hacer una transformacion de los datos
#-- # se va a hacer a partir de la familia de transformaciones Box-Tidwell
boxTidwell(y~x, data=Datos6) #No pongas el modelo, si no los datos
#Problema 6 de los Pinguinos, echo por: Fernando Alvarado Palacios
#Librerias necesarias para el ejercicio
library(dplyr)
library(kableExtra)
library(ggplot2)
library(lmtest) # checar homocedasticidad
library(car) # checar linealidad
#Limpiando la consola para poder trabajar mejor
rm(list = ls(all.names = TRUE))
gc()
#Datos sobre los pinguinos
x = c(79, 93, 100, 105, 85, 101, 96, 96, 109, 70, 71, 87)
y = c(119, 142, 158, 157, 136, 151, 139, 142, 165, 117, 123, 130)
Datos6 = data.frame(cbind(x, y))
kable(t(Datos6)) %>%
kable_styling(bootstrap_options = "striped", full_width = F)
#Ajusstando el modelo de regresion lineal
modelo = lm(y ~ x, data = Datos6)
summary(modelo)
#-- Con este primer vistazo podemos observar que si tienen relacion las variables x, y en el modelo de regresion lineal
#Graficando el modelo de regresion lineal
grafica_modelo = function(varx) {
ggplot(Datos6, aes(x = varx, y = y)) + #Creando la grafica de nuetra regresion lineal, agustado con los datos de los pinguinos
geom_point() +
geom_smooth(method = "lm", se = F) +
labs(title = "Modelo de regresion lineal",
x = "x peso del huevo menor",
y = "y peso del huevo mayor") +
theme_minimal()
}
grafica_modelo(x)
#Verificando si se cumplen los supuestos del modelo de regresion lineal
#Checando  homocedasticidad por medio de la grafica propia de R
plot(modelo, 3)#Checar homocedasticidad, por defecto en R
#Aplicando la una prueba de hipotesis para la homocedasticidad
lmtest::bptest(modelo)
#-- Con esta prueba de Hipoteis como nuestro p-value es 0.5036, podemos concluir que tenemos homocedasticidad
#Checando linealidad  por medio de la grafica de R
plot(modelo, 1)#Checar linealidad, por defecto en R
#-- Con esta grafica podemos observar que no se esta cumpliendo el supuesto de linealidad, por lo que tendremso que hacer una transformacion de los datos
#-- # se va a hacer a partir de la familia de transformaciones Box-Tidwell
boxTidwell(y~x, data=Datos6) #No pongas el modelo, si no los datos
#-- Con esta prueba podemos observar que es necesrio hacer una transformacion de los datos
#Ajustando nuestro modelo de Regresion Lineal con una transformacion
lambda <- boxTidwell_result$estimate[1]  # Extraer el valor de lambda de la prueba de Box-Tidwell
summary(modelo_transformado) #Checando el resumen del modelo
#Volciendo a hacer el modelo de regresion
modelo_transformado = lm(y ~ x_transformed, data = Datos6)
lambda <- boxTidwell_result$estimate[1]  # Extraer el valor de lambda de la prueba de Box-Tidwell
lambda <- boxTidwell_result$estimate[1]  # Extraer el valor de lambda de la prueba de Box-Tidwell
library(dplyr)
library(kableExtra)
library(ggplot2)
library(lmtest) # checar homocedasticidad
library(car) # checar linealidad
library(dplyr)
library(kableExtra)
library(ggplot2)
library(lmtest) # checar homocedasticidad
library(car) # checar linealidad
#Limpiando la consola para poder trabajar mejor
rm(list = ls(all.names = TRUE))
gc()
#Datos sobre los pinguinos
x = c(79, 93, 100, 105, 85, 101, 96, 96, 109, 70, 71, 87)
y = c(119, 142, 158, 157, 136, 151, 139, 142, 165, 117, 123, 130)
Datos6 = data.frame(cbind(x, y))
kable(t(Datos6)) %>%
kable_styling(bootstrap_options = "striped", full_width = F)
#Ajusstando el modelo de regresion lineal
modelo = lm(y ~ x, data = Datos6)
summary(modelo)
#-- Con este primer vistazo podemos observar que si tienen relacion las variables x, y en el modelo de regresion lineal
#Graficando el modelo de regresion lineal
grafica_modelo = function(varx) {
ggplot(Datos6, aes(x = varx, y = y)) + #Creando la grafica de nuetra regresion lineal, agustado con los datos de los pinguinos
geom_point() +
geom_smooth(method = "lm", se = F) +
labs(title = "Modelo de regresion lineal",
x = "x peso del huevo menor",
y = "y peso del huevo mayor") +
theme_minimal()
}
grafica_modelo(x)
plot(modelo, 3)#Checar homocedasticidad, por defecto en R
lmtest::bptest(modelo)
plot(modelo, 1)#Checar linealidad, por defecto en R
#-- Con esta grafica podemos observar que no se esta cumpliendo el supuesto de linealidad, por lo que tendremso que hacer una transformacion de los datos
#-- # se va a hacer a partir de la familia de transformaciones Box-Tidwell
boxTidwell(y~x, data=Datos6) #No pongas el modelo, si no los datos
lambda <- boxTidwell_result$estimate[1]  # Extraer el valor de lambda de la prueba de Box-Tidwell
#-- Con esta grafica podemos observar que no se esta cumpliendo el supuesto de linealidad, por lo que tendremso que hacer una transformacion de los datos
#-- # se va a hacer a partir de la familia de transformaciones Box-Tidwell
pruebaBox_Tid <- boxTidwell(y~x, data=Datos6) #No pongas el modelo, si no los datos
pruebaBox_Tid
lambda <- pruebaBox_Tid$estimate[1]  # Extraer el valor de lambda de la prueba de Box-Tidwell
Datos6$x_transformed <- Datos$x^lambda    # Aplicar la transformación
#Volciendo a hacer el modelo de regresion
modelo_transformado = lm(y ~ x_transformed, data = Datos6)
Datos6$x_transformed <- Datos6$x^lambda    # Aplicar la transformación
Datos6$x_transformed <- Datos6$x^lambda    # Aplicar la transformación
lambda
pruebaBox_Tid
lambda <- pruebaBox_Tid$estimate[0]  # Extraer el valor de lambda de la prueba de Box-Tidwell
lambda
lambda <- pruebaBox_Tid$estimate[1]  # Extraer el valor de lambda de la prueba de Box-Tidwell
lambda <- pruebaBox_Tid$lambda  # Extraer el valor de lambda de la prueba de Box-Tidwell
lambda
lambda <- pruebaBox_Tid$estimate[1]  # Extraer el valor de lambda de la prueba de Box-Tidwell
lambda
lambda <- 3.603
Datos6$x_transformed <- Datos6$x^lambda    # Aplicar la transformación
Datos6
modelo_transformado = lm(y ~ x_transformed, data = Datos6)
summary(modelo_transformado) #Checando el resumen del modelo
grafica_modelo(x_transformed) #Graficando el modelo de regresion lineal transformado
Datos6
#Volciendo a hacer el modelo de regresion
modelo_transformado = lm(y ~ x_transformed, data = Datos6)
summary(modelo_transformado) #Checando el resumen del modelo
grafica_modelo(Datos6$x_transformed) #Graficando el modelo de regresion lineal transformado
#Ejercicio 5, echo por: Fernando Alvarado Palacios
#Limpiando la consola para poder trabajar mejor
rm(list = ls(all.names = TRUE))
gc()
#Limpiando la consola para poder trabajar mejor
rm(list = ls(all.names = TRUE))
gc()
#Librerias necesarias para el ejercicio
library(dplyr)
library(kableExtra)
library(ggplot2)
library(lmtest) # checar homocedasticidad
library(car) # checar linealidad
library(broom) # checar normalidad y calcular residuales
library(lawstat) #libreria para checar aleatoriedad
#Estableciendo el directorio de trabajo
getwd()
setwd("C://Users//ferna//Documents//Estadisitica_2//data//Ejercicio_5")#Modificar esta linea en caso de que no se encuentre en la misma carpeta
#Importadno los datos para trabajar
dataSal = read.csv("./Datos.csv")
#Graficando el modelo de regresion lineal, para poder visualizar los datos
grafica_modelo = function(varx, vary) {
ggplot(dataSal, aes(x = varx, y = vary)) + #Creando la grafica de nuetra regresion lineal, agustado con los datos de los pinguinos
geom_point() +
geom_smooth(method = "lm", se = F) +
labs(title = "Modelo de regresion lineal",
x = "x peso del huevo menor",
y = "y peso del huevo mayor") +
theme_minimal()
}
#Inciso a y b, los junte por que quise dar el modelo, grafica y luegos las respectivas transformaciones y sus respectivas graficas
#Proponiendo un primer modelo de regresion lineal para nuestros datos
modelo = lm(years ~ salary, data = dataSal)
summary(modelo)
#-- Con este primer vistaso podemos concluir que los datos si tienne una relacion y podemos aplicar un modelo de regresion lineal
grafica_modelo(dataSal$salary, dataSal$years) #grafica del modelo sin transformar
#Verificando si se cumplen los supuestos del modelo de regresion lineal
#Checando linealidad
plot(modelo, 1)#Checar linealidad, por defecto en R, de primera vista parece que no es lineal
#Aplicando una prueba de hip para verificarlo
boxTidwell(years ~ salary, data=dataSal) #Con esto verificamos que no es lineal y ocupamos aplicar untra trasformacion ln
#Aplicando otrara trnasformacion a los datos para ver como se veria graficamente
dataSal$transformed2 = dataSal$salary^2 #Aplicando la transformacion cuadratica a los datos
modeloIncA = lm(years ~ transformed, data = dataSal) #Modelo con la transformacion cuadratica
#Limpiando la consola para poder trabajar mejor
rm(list = ls(all.names = TRUE))
gc()
#Problema 5, talba Anova echo por: Fernando Alvarado Palacios
#Limpiando la consola para poder trabajar mejor
rm(list = ls(all.names = TRUE))
gc()
#Librerias necesarias para el ejercicio
library(kableExtra)
library(ggplot2) #Graficar
library(lmtest) # checar homocedasticidad
library(car) # checar linealidad
library(broom) # checar normalidad y calcular residuales
library(lawstat) #libreria para checar aleatoriedad
library(tidyverse) #Libreria para hacer la manipulacion de los datos
library(dplyr) #Meanejo de datos
#Estableciendo el directorio de trabajo
getwd()
setwd("C://Users//ferna//Documents//Estadisitica_2//Data//Proyecto 1//Ejercicio_5")#Modificar esta linea en caso de que no se encuentre en la misma carpeta
#Cargando nuestros datos
dataMed = read.csv("./Ejercicio5A.csv") #Archivo CSV con los datos de los medicamentos
#Donde Y es un índice de carga viral y Med es una variable con dos niveles dependiendo si se aplicó o no el nuevo medicamento y Edad es la edad del paciente
str(dataMed) #Cargando una vista previa de nuestros datos
#--Podemos observar que que tenemos 3 variables,  una de tipo numerico y dos de tipo caracter
#Vamos a modificar los datos de tipo caracter a categoricos para poder trabajar con ellos
dataMed$Med = as.factor(dataMed$Med)
dataMed$Edad = as.factor(dataMed$Edad)
str(dataMed) #Cargando una vista previa de nuestros datos
#Vamos a hacer una filtracion de los dato
dataFil = dataMed %>% dplyr::select(Y, Med)  %>% filter (Med %in% c("Si", "No"))  #Filtrando los datos para solo tener dos categorias
levels(dataFil$Med) <- list(Si = "Si", No = "No") #Cambiamos los nombres de las categorias
dataFil
#Inciso I, vamos a realizar un analisis exploratorio de los datos, para ellos vamos a realizar un boxplot
boxplot(Y ~ Med, data = dataFil, col = "white", outline=FALSE)
stripchart(Y ~ Med, data = dataFil,
method = "jitter",
pch = 19,
col = 2:4,
vertical = TRUE,
add = TRUE)
#--Con esta dispersion de los puntos que tenemos podeos concluir que no estamos teniendo homoceasticidad en nuestros datos (por la disspersion vertical de los puntos)
#Crenado nuestro modelo de regresion lineal
modelo = lm(Y ~ Med, data = dataFil) #Modelo base con el vamos a trbaajar
summary(modelo) #Cargando un resumen de nuestro modelo, con esto podemos ver que Y y Med tienen una relacion
#Verificando los Supuestos del modelo de regresion lineal
plot(modelo, 3)#Checar homocedasticidad, por defecto en R
lmtest::bptest(modelo)
#-- Con esta prueba de Hipoteis como nuestro p-value es 0.2594, podemos concluir que tenemos homocedasticidad
car::ncvTest(modelo) #Otra funcion para checar homocedasticidad
plot(modelo, 2)#Checar normalidad, por defecto en R
ResiduosModelo = augment(modelo) #Arreglando los residuales de nuestro modelo
head(ResiduosModelo) #Veamos que nos regresa la funcion augment
shapiro.test(ResiduosModelo$.std.resid)
#El valor de este pruena fue de 0.06098, casi se rechaza, ver si haciendo una transformacion a los datos se puede mejorar
#Otra prueba ms robusta de normalidad en cada grupo y sobre la variable dependiente
dataFil
shapiro.test(dataFil$Y[dataFil$Med=="Si"])
nortest::lillie.test(dataFil$Y[dataFil$Med=="Si"])
tseries::jarque.bera.test(dataFil$Y[dataFil$Med=="Si"])
shapiro.test(dataFil$Y[dataFil$Med=="No"])
nortest::lillie.test(dataFil$Y[dataFil$Med=="No"])
tseries::jarque.bera.test(dataFil$Y[dataFil$Med=="No"])
#Con estas preubas individuales tuvimos un mejor resultado, por lo que podemos concluir que tenemos normalidad en cada grupo y sobre la varible dependiente
#resumen del modelo y tests
summary(modelo)
AIC(modelo)
BIC(modelo)
#-------------------------------------------------------------------------------------------
#Notas:
#-------------------------------------------------------------------------------------------
#En este caso, para ver lsa preubas del modelo tengo que hacer las pruebas para ambos modelos
# El profe, como tenia ambas variables categoricas en una sola columan pudo hacer 1 preuba
#para ambas cosas
#
#
#
#Creando otro filtro para trabajar con los datos, separando las dos clases (A quienes se les aplico el medicamento y a quienes no)
View(dataFil)
View(dataMed)
dataFil
MatPrueba1 = matrix(c(0,1), ncol=2, nrow=1)
c=0
prueba1 = glht(fitln, linfct=MatPrueba1, rhs=c, alternative ="greater")
library(multcomp) #Libreria para hacer pruebas de hipotesis
MatPrueba1 = matrix(c(0,1), ncol=2, nrow=1)
c=0
prueba1 = glht(fitln, linfct=MatPrueba1, rhs=c, alternative ="greater")
#Creando la prueba de hipotesis para comprobar la prueba la hipotesis de relacion entre la carga viral y el medicamento
MatPrueba1 = matrix(c(0,1), ncol=2, nrow=1)
c=0
prueba1 = glht(fitln, linfct=MatPrueba1, rhs=c, alternative ="greater")
prueba1 = glht(modelo, linfct=MatPrueba1, rhs=c, alternative ="greater")
summary(prueba1)
MatPrueba1 = matrix(c(0,1), ncol=2, nrow=1)
c=0
prueba1 = glht(modelo, linfct=MatPrueba1, rhs=c, alternative ="greater")
summary(prueba1)
#Creando la prueba de hipotesis para comprobar la prueba la hipotesis de relacion entre la carga viral y el medicamento
MatPrueba1 = matrix(c(1,0), ncol=2, nrow=1)
c=0
prueba1 = glht(modelo, linfct=MatPrueba1, rhs=c, alternative ="greater")
summary(prueba1)
#Inciso IV, Vemos que el costo del medicamento es considerable, y nos dieron una nueva variable, la edad, vamos a ver si la edad influye en la carga viral
str(dataMed) #Cargando una vista previa de nuestros datos
summary(dataMed) #Cargando un resumen de nuestros
dataMed
#Como tenemos mas personas en el caso donde son >60, vamos a hacer el modelo en base a esa poblacion
dataFil2 = dataMed %>% dplyr::select(Y, Med)  %>% filter (Edad  ">60")  #Filtrando los datos para solo tener dos categorias
dataFil2 = dataMed %>% dplyr::select(Y, Med)  %>% filter (Edad  == ">60")  #Filtrando los datos para solo tener dos categorias
dataFil2 = dataMed %>% dplyr::select(Y, Med)  %>% filter (Edad  == 2)  #Filtrando los datos para solo tener dos categorias
dataFil2 = dataMed %>% dplyr::select(Y, Med)  %>% filter (Edad %in% c("<=60", ">60"))  #Filtrando los datos para solo tener dos categorias
dataFil2 = dataMed %>% dplyr::select(Y, Med, Edad)  %>% filter (Edad %in% c("<=60", ">60"))  #Filtrando los datos para solo tener dos categorias
summary(dataFil2) #Cargando un resumen de nuestros
dataFil2 = dataMed %>% dplyr::select(Y, Med, Edad)  %>% filter (Edad== ">60") #Filtrando los datos para solo tener dos categorias
summary(dataFil2) #Cargando un resumen de nuestros
dataFil2 = dataMed %>%  filter dplyr::(Edad== ">60")   %>%  select(Y, Med) #Filtrando los datos para solo tener dos categorias
dataFil2 = dataMed %>%  dplyr::filter(Edad== ">60")   %>%  select(Y, Med) #Filtrando los datos para solo tener dos categorias
dataFil2 <- dataMed %>%
filter(Edad ">60") %>%
dataFil2 <- dataMed %>%
filter(Edad ==">60") %>%
select(Y, Med)  # Asegúrate de que Y y Med son los nombres correctos
dataFil2 = dataMed %>% dplyr::select(Y, Med, Edad)  %>% filter (Edad== ">60"))  #Filtrando los datos para solo tener dos categorias
dataFil2 = dataMed %>% dplyr::select(Y, Med, Edad)  %>% filter (Edad== ">60") #Filtrando los datos para solo tener dos categorias
summary(dataFil2) #Cargando un resumen de nuestros
dataFil2 = dataMed %>% dplyr::select(Y, Med, Edad)  %>% filter (Edad== ">60")  %>% select(Y, Med)  #Filtrando los datos para solo tener dos categorias
dataFil2 = dataMed %>% dplyr::select(Y, Med, Edad)  %>% filter (Edad== ">60")   #Filtrando los datos para solo tener dos categorias
summary(dataFil2) #Cargando un resumen de nuestros
Volviendo a hacer nuestro modelo de regresion lineal
#Volviendo a hacer nuestro modelo de regresion lineal
modeloEdad = lm(Y ~ Med, data = dataFil2) #Modelo base con el vamos a trbaajar
summary(modeloEdad) #Cargando un resumen de nuestro modelo, con esto podemos ver que Y y Med tienen una relacion
summary(dataMed) #Cargando un resumen de nuestros
#Como tenemos mas personas en el caso donde son >60, vamos a hacer el modelo en base a esa poblacion
dataFil2 = dataMed %>% dplyr::select(Y, Med, Edad)  %>% filter (Edad== ">60")   #Filtrando los datos para solo tener dos categorias
summary(dataFil2) #Cargando un resumen de nuestros
#Volviendo a hacer nuestro modelo de regresion lineal
modeloEdad = lm(Y ~ Med, data = dataFil2) #Modelo base con el vamos a trbaajar
summary(modeloEdad) #Cargando un resumen de nuestro modelo, con esto podemos ver que Y y Med tienen una relacion de nuevo filtrando con la edad
#Checando pruebas del modelo de regresion de nuevo
plot(modeloEdad, 3)#Checar homocedasticidad, por defecto en R
lmtest::bptest(modeloEdad)
#-- Con esta prueba de Hipoteis como nuestro p-value es 0.2594, podemos concluir que tenemos homocedasticidad
car::ncvTest(modeloEdad) #Otra funcion para checar homocedasticidad
plot(modeloEdad, 2)#Checar normalidad, por defecto en R
ResiduosModeloEdad = augment(modeloEdad) #Arreglando los residuales de nuestro modelo
head(ResiduosModeloEdad) #Veamos que nos regresa la funcion augment
shapiro.test(ResiduosModeloEdad$.std.resid)
#Otra prueba ms robusta de normalidad en cada grupo y sobre la variable dependiente
dataFil2
shapiro.test(dataFil2$Y[dataFil2$Med=="Si"])
nortest::lillie.test(dataFil2$Y[dataFil2$Med=="Si"])
tseries::jarque.bera.test(dataFil2$Y[dataFil2$Med=="Si"])
shapiro.test(dataFil2$Y[dataFil2$Med=="No"])
nortest::lillie.test(dataFil2$Y[dataFil2$Med=="No"])
tseries::jarque.bera.test(dataFil2$Y[dataFil2$Med=="No"])
#resumen del modelo y tests, para ver que tan bueno es
summary(modeloEdad)
AIC(modeloEdad)
BIC(modeloEdad)
#Haciedno la misma preuba de hipotesis que hicimos en el inciso III para ver si el medicamento sigue funcionando en relacion a la carga viral
MatPrueba2 = matrix(c(0,1), ncol=2, nrow=1)
c=0
prueba2 = glht(modeloEdad, linfct=MatPrueba2, rhs=c, alternative ="greater")
summary(prueba2)
#Haciedno la misma preuba de hipotesis que hicimos en el inciso III para ver si el medicamento sigue funcionando en relacion a la carga viral
#Donte tambien estamos comparando H_o: b1 <= 0 vs H_a: b1 > 0
MatPrueba2 = matrix(c(0,1), ncol=2, nrow=1)
c=0
prueba2 = glht(modeloEdad, linfct=MatPrueba2, rhs=c, alternative ="greater")
summary(prueba2)
#En este caso estamos viendo que se acepto h_0, lo que significa que no hay una relacion positiva entre la carga viral y la aplicacion del medicamento
#Por lo que podriamos concluir que el medicamento no funciona y para "maquillar", los datos, agregaron poblacion joven
summary(dataMed) #Cargando un resumen de nuestros
ggplot(data = dataMed, aes(x = interaction(Med, Edad), y = Y)) +
geom_boxplot() +
labs(x = "Edad y si estaban vacunado", y = "Carga retroviral") +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
ggplot(data = dataMed, aes(x = interaction(Med, Edad), y = Y)) +
geom_boxplot() +
labs(x = "Edad y si estaban vacunado", y = "Carga retroviral") +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
stripchart(Y ~ Med, data = dataFil,
method = "jitter",
pch = 19,
col = 2:4,
vertical = TRUE,
add = TRUE)
stripchart(Y ~ Med, data = dataFil,
method = "jitter",
pch = 19,
col = 2:4,
vertical = TRUE,
add = TRUE)
ggplot(data = dataMed, aes(x = interaction(Med, Edad), y = Y)) +
geom_boxplot() +
labs(x = "Edad y si estaban vacunado", y = "Carga retroviral") +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
stripchart(Y ~ Med, data = dataMed,
method = "jitter",
pch = 19,
col = 2:4,
vertical = TRUE,
add = TRUE)
boxplot(Y ~ Med, data = dataFil, col = "white", outline=FALSE)
stripchart(Y ~ Med, data = dataFil,
method = "jitter",
pch = 19,
col = 2:4,
vertical = TRUE,
add = TRUE)
